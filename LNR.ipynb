{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataframe: (1348, 5)\n",
      "First 5 rows of the dataframe:\n",
      "    id                                              title  \\\n",
      "0  391      پاکستانی طلبا عالمی نیوکلیئر اولمپیاڈ اعزازات   \n",
      "1   76                              ملک آج ڈالر قیمت رہی   \n",
      "2  280  امریکی سینیٹ اسرائیل اسلحے فروخت روکنے متعلق  ...   \n",
      "3   63    پاکستان سعودی عرب درآمدات کمی ایران انحصار بڑھ   \n",
      "4  114            غزہ اسرائیل رہائشی بمباری  فلسطینی شہید   \n",
      "\n",
      "                                 link  \\\n",
      "0    https://jang.com.pk/news/1378483   \n",
      "1  https://urdu.geo.tv/latest/387502-   \n",
      "2  https://urdu.geo.tv/latest/387551-   \n",
      "3  https://urdu.geo.tv/latest/387804-   \n",
      "4    https://urdu.samaa.tv/2087325042   \n",
      "\n",
      "                                             content          gold_label  \n",
      "0  پاکستانی طلبا بین الاقوامی نیوکلیئر سائنس اولم...  science-technology  \n",
      "1  کراچی ملکی تبادلہ منڈیوں ڈالر قیمت اضافہ ہوگیا...            business  \n",
      "2  واشنگٹن امریکی سینیٹ اسرائیل غزہ جنگ اسلحے فرو...       international  \n",
      "3  اسلام آباد رواں مالی سال پاکستان سعودی عرب در...            business  \n",
      "4  عالمی فوجداری عدالت نیتن یاہو وارنٹ گرفتاری جا...       international  \n",
      "Labels: ['science-technology' 'business' 'international' 'sports' 'entertainment']\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv('cleaned_combined_articles.csv')\n",
    "print(\"Shape of the dataframe:\", data.shape)\n",
    "print(\"First 5 rows of the dataframe:\")\n",
    "print(data.head())\n",
    "texts = data['content'] \n",
    "labels = pd.get_dummies(data['gold_label']).values \n",
    "labels_list = data['gold_label'].unique()\n",
    "print(\"Labels:\", labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "def tokenize(text):\n",
    "    return text.lower().split()\n",
    "\n",
    "vocab = set()\n",
    "tokenized_texts = []\n",
    "for text in texts:\n",
    "    tokens = tokenize(text)\n",
    "    tokenized_texts.append(tokens)\n",
    "    vocab.update(tokens)\n",
    "\n",
    "vocab = sorted(vocab)  \n",
    "vocab_ind = {word: idx for idx, word in enumerate(vocab)}\n",
    "def vectorize(tokens, vocab_ind):\n",
    "    vect = np.zeros(len(vocab_ind))\n",
    "    for token in tokens:\n",
    "        if token in vocab_ind:\n",
    "            vect[vocab_ind[token]] += 1\n",
    "    return vect\n",
    "\n",
    "vect_bow = np.array([vectorize(tokens, vocab_ind) for tokens in tokenized_texts])\n",
    "train_x, test_x, train_y, test_y = train_test_split(vect_bow, labels, test_size=0.25, random_state=42)\n",
    "\n",
    "print(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressionScratch:\n",
    "    def __init__(self, lr=0.01, epochs=1000):\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        n_classes = y.shape[1]\n",
    "        self.weights = np.zeros((n_features, n_classes))\n",
    "        self.bias = np.zeros(n_classes)\n",
    "\n",
    "        for _ in range(self.epochs):\n",
    "            linear_model = np.dot(X, self.weights) + self.bias\n",
    "            predictions = self.sigmoid(linear_model)\n",
    "\n",
    "            # Compute gradients\n",
    "            dw = (1 / n_samples) * np.dot(X.T, (predictions - y))\n",
    "            db = (1 / n_samples) * np.sum(predictions - y, axis=0)\n",
    "\n",
    "            # Update weights and bias\n",
    "            self.weights -= self.lr * dw\n",
    "            self.bias -= self.lr * db\n",
    "\n",
    "    def predict(self, X):\n",
    "        linear_model = np.dot(X, self.weights) + self.bias\n",
    "        probabilities = self.sigmoid(linear_model)\n",
    "        # for i in range(len(X)):\n",
    "        #     print(f\"Text: {texts.iloc[i]}\")\n",
    "        #     print(f\"Predicted Label: { labels_list[np.argmax(probabilities[i])]}\")\n",
    "        #     print(f\"Actual Label: { labels_list[np.argmax(test_y[i])]}\\n\")\n",
    "            \n",
    "        return np.argmax(probabilities, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 95.85%\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98        70\n",
      "           1       0.94      0.99      0.96        76\n",
      "           2       0.94      0.94      0.94        66\n",
      "           3       0.96      0.92      0.94        50\n",
      "           4       0.99      0.95      0.97        75\n",
      "\n",
      "    accuracy                           0.96       337\n",
      "   macro avg       0.96      0.96      0.96       337\n",
      "weighted avg       0.96      0.96      0.96       337\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mod = LogisticRegressionScratch(lr=0.1, epochs=1000)\n",
    "mod.fit(train_x, train_y)\n",
    "y_test_ind = np.argmax(test_y, axis=1)\n",
    "y_pred_ind = mod.predict(test_x)\n",
    "acc = accuracy_score(y_test_ind, y_pred_ind)\n",
    "print(f\"Accuracy: {acc:.2%}\")\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_test_ind, y_pred_ind))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
